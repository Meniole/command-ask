import { Context } from "../types";
import { CompletionsType } from "../adapters/openai/helpers/completions";
import { CommentSimilaritySearchResult } from "../adapters/supabase/helpers/comment";
import { IssueSimilaritySearchResult } from "../adapters/supabase/helpers/issues";
import { recursivelyFetchLinkedIssues } from "../helpers/issue-fetching";
import { formatChatHistory } from "../helpers/format-chat-history";
import { fetchRepoDependencies, fetchRepoLanguageStats } from "./ground-truths/chat-bot";
import { findGroundTruths } from "./ground-truths/find-ground-truths";
import { bubbleUpErrorComment, logger } from "../helpers/errors";

/**
 * Asks a question to GPT and returns the response
 * @param context - The context object containing environment and configuration details
 * @param question - The question to ask GPT
 * @returns The response from GPT
 * @throws If no question is provided
 */
export async function askQuestion(context: Context, question: string) {
  if (!question) {
    throw context.logger.error("No question provided");
  }
  const { specAndBodies, streamlinedComments } = await recursivelyFetchLinkedIssues({
    context,
    owner: context.payload.repository.owner.login,
    repo: context.payload.repository.name,
  });
  const formattedChat = await formatChatHistory(context, streamlinedComments, specAndBodies);
  logger.info(`${formattedChat.join("")}`);
  return await askLlm(context, question, formattedChat);
}

/**
 * Asks GPT a question and returns the completions
 * @param context - The context object containing environment and configuration details
 * @param question - The question to ask GPT
 * @param formattedChat - The formatted chat history to provide context to GPT
 * @returns completions - The completions generated by GPT
 **/
export async function askLlm(context: Context, question: string, formattedChat: string[]): Promise<CompletionsType> {
  const {
    env: { UBIQUITY_OS_APP_NAME },
    config: { model, similarityThreshold, maxTokens },
    adapters: {
      supabase: { comment, issue },
      voyage: { reranker },
      openai: { completions },
    },
  } = context;

  try {
    const [similarComments, similarIssues] = await Promise.all([
      comment.findSimilarComments(question, 1 - similarityThreshold, ""),
      issue.findSimilarIssues(question, 1 - similarityThreshold, ""),
    ]);

    const similarText = [
      ...(similarComments?.map((comment: CommentSimilaritySearchResult) => comment.comment_plaintext) || []),
      ...(similarIssues?.map((issue: IssueSimilaritySearchResult) => issue.issue_plaintext) || []),
    ];

    formattedChat = formattedChat.filter((text) => text);

    const rerankedText = similarText.length > 0 ? await reranker.reRankResults(similarText, question) : [];
    const [languages, { dependencies, devDependencies }] = await Promise.all([fetchRepoLanguageStats(context), fetchRepoDependencies(context)]);

    let groundTruths: string[] = [];

    if (!languages.length) {
      groundTruths.push("No languages found in the repository");
    }

    if (!Reflect.ownKeys(dependencies).length) {
      groundTruths.push("No dependencies found in the repository");
    }

    if (!Reflect.ownKeys(devDependencies).length) {
      groundTruths.push("No devDependencies found in the repository");
    }

    if (groundTruths.length === 3) {
      return await completions.createCompletion(question, model, rerankedText, formattedChat, groundTruths, UBIQUITY_OS_APP_NAME, maxTokens);
    }

    groundTruths = await findGroundTruths(context, "chat-bot", { languages, dependencies, devDependencies });
    return await completions.createCompletion(question, model, rerankedText, formattedChat, groundTruths, UBIQUITY_OS_APP_NAME, maxTokens);
  } catch (error) {
    throw bubbleUpErrorComment(context, error, false);
  }
}
