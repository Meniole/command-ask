import { Context } from "../types";
import { CompletionsType } from "../adapters/openai/helpers/completions";
import { CommentSimilaritySearchResult } from "../adapters/supabase/helpers/comment";
import { IssueSimilaritySearchResult } from "../adapters/supabase/helpers/issues";
import { recursivelyFetchLinkedIssues } from "../helpers/issue-fetching";
import { formatChatHistory } from "../helpers/format-chat-history";
import { fetchRepoDependencies, fetchRepoLanguageStats } from "./ground-truths/chat-bot";
import { findGroundTruths } from "./ground-truths/find-ground-truths";
import { bubbleUpErrorComment } from "../helpers/errors";

/**
 * Asks a question to GPT and returns the response
 * @param context - The context object containing environment and configuration details
 * @param question - The question to ask GPT
 * @returns The response from GPT
 * @throws If no question is provided
 */
export async function askQuestion(context: Context, question: string) {
  if (!question) {
    throw context.logger.error("No question provided");
  }
  const { specAndBodies, streamlinedComments } = await recursivelyFetchLinkedIssues({
    context,
    owner: context.payload.repository.owner.login,
    repo: context.payload.repository.name,
  });
  const formattedChat = await formatChatHistory(context, streamlinedComments, specAndBodies);
  context.logger.info(`${formattedChat.join("")}`);
  return await askGpt(context, question, formattedChat);
}

/**
 * Asks GPT a question and returns the completions
 * @param context - The context object containing environment and configuration details
 * @param question - The question to ask GPT
 * @param formattedChat - The formatted chat history to provide context to GPT
 * @returns completions - The completions generated by GPT
 **/
export async function askGpt(context: Context, question: string, formattedChat: string[]): Promise<CompletionsType> {
  const {
    env: { UBIQUITY_OS_APP_NAME },
    config: { model, similarityThreshold, maxTokens },
  } = context;
  let similarComments: CommentSimilaritySearchResult[] = [];
  let similarIssues: IssueSimilaritySearchResult[] = [];
  try {
    similarComments = (await context.adapters.supabase.comment.findSimilarComments(question, 1 - similarityThreshold, "")) || [];
  } catch (error) {
    throw bubbleUpErrorComment(context, error, false);
  }
  try {
    similarIssues = (await context.adapters.supabase.issue.findSimilarIssues(question, 1 - similarityThreshold, "")) || [];
  } catch (error) {
    throw bubbleUpErrorComment(context, error, false);
  }
  let similarText = similarComments.map((comment: CommentSimilaritySearchResult) => comment.comment_plaintext);
  similarText.push(...similarIssues.map((issue: IssueSimilaritySearchResult) => issue.issue_plaintext));
  // Remove Null Results (Private Comments)
  similarText = similarText.filter((text) => text !== null);
  formattedChat = formattedChat.filter((text) => text !== null);
  similarText = similarText.filter((text) => text !== "");
  const rerankedText = similarText.length > 0 ? await context.adapters.voyage.reranker.reRankResults(similarText, question) : [];
  const languages = await fetchRepoLanguageStats(context);
  let dependencies = {};
  let devDependencies = {};
  try {
    const deps = await fetchRepoDependencies(context);
    dependencies = deps.dependencies;
    devDependencies = deps.devDependencies;
  } catch (error) {
    throw bubbleUpErrorComment(context, error, false);
  }
  const groundTruths = await findGroundTruths(context, "chat-bot", {
    languages,
    dependencies,
    devDependencies,
  });
  //Calculate the current context size in tokens
  const numTokens = await context.adapters.openai.completions.findTokenLength(question, rerankedText, formattedChat, groundTruths);
  context.logger.info(`Number of tokens: ${numTokens}`);
  return context.adapters.openai.completions.createCompletion(question, model, rerankedText, formattedChat, groundTruths, UBIQUITY_OS_APP_NAME, maxTokens);
}
